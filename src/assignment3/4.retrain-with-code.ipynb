{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# extract text from resumes, output to jsonl\n",
    "\n",
    "import re\n",
    "import json\n",
    "import spacy as spacy\n",
    "import srsly\n",
    "'''\n",
    "Make a \"rehearsal\" update to the models in the pipeline, to prevent forgetting. Rehearsal updates run an initial copy of the model over some data, and update the model so its current predictions are more like the initial ones. This is useful for keeping a pretrained model on-track, even if you're updating it with a smaller set of examples.\n",
    "'''\n",
    "\n",
    "# avoids JSONDecodeError due to malformed json file\n",
    "data = [json.loads(line)\n",
    "        for line in open(\"../../data/annotated/resumedata.json\", \"r\", encoding=\"utf-8\")]\n",
    "\n",
    "content = []\n",
    "for k in data:\n",
    "    dct = {\n",
    "        \"text\": re.sub(r\"\\s+\", \" \", k[\"content\"])\n",
    "    }\n",
    "    content.append(dct)\n",
    "\n",
    "srsly.write_json(\"../../data/resume.jsonl\", content)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T01:14:33.559568Z",
     "start_time": "2023-07-23T01:14:33.492409Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [],
   "source": [
    "# create a silver annotated dataset\n",
    "'''\n",
    "Rehearsal updates run an initial copy of the model over some data\n",
    "'''\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "with open(\"../../data/resume.jsonl\", \"r\", encoding=\"utf-8\") as f1:\n",
    "    resume = json.load(f1)\n",
    "\n",
    "    annotated = list()\n",
    "    for k in resume:\n",
    "        doc = nlp(k[\"text\"])\n",
    "        for sent in doc.sents:\n",
    "            labels = list()\n",
    "            for e in sent.ents:\n",
    "                labels.append([e.start_char, e.end_char, e.label_])\n",
    "            if labels:\n",
    "                spacy_entry = (sent.text, {\"entities\": labels})\n",
    "                annotated.append(spacy_entry)\n",
    "\n",
    "    srsly.write_json(\"../../data/annotated/rehearse_silver_spacy.jsonl\", annotated)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T04:36:58.538216Z",
     "start_time": "2023-07-23T04:36:39.118416Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [],
   "source": [
    "# convert echr training data to jsonl file so that we can train a spacy model\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "doc_bin = DocBin().from_disk(\"../../data/annotated/train.spacy\")\n",
    "examples = []\n",
    "for doc in doc_bin.get_docs(nlp.vocab):\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.start_char, ent.end_char, ent.label_))\n",
    "\n",
    "    spacy_entry = (doc.text, {\"entities\": entities})\n",
    "    examples.append(spacy_entry)\n",
    "\n",
    "    srsly.write_json(\"../../data/annotated/echr_train_spacy.jsonl\", examples)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T05:34:37.853831Z",
     "start_time": "2023-07-23T05:34:02.987274Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert echr training data to jsonl file so that we can test a spacy model\n",
    "\n",
    "doc_bin = DocBin().from_disk(\"../../data/annotated/dev.spacy\")\n",
    "examples = []\n",
    "for doc in doc_bin.get_docs(nlp.vocab):\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.start_char, ent.end_char, ent.label_))\n",
    "\n",
    "    spacy_entry = (doc.text, {\"entities\": entities})\n",
    "    examples.append(spacy_entry)\n",
    "\n",
    "    srsly.write_json(\"../../data/annotated/echr_dev_spacy.jsonl\", examples)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[158], line 29\u001B[0m\n\u001B[1;32m     27\u001B[0m         doc \u001B[38;5;241m=\u001B[39m nlp\u001B[38;5;241m.\u001B[39mmake_doc(raw_text)\n\u001B[1;32m     28\u001B[0m         example \u001B[38;5;241m=\u001B[39m Example\u001B[38;5;241m.\u001B[39mfrom_dict(doc,entity_offsets)\n\u001B[0;32m---> 29\u001B[0m         \u001B[43mnlp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mexample\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43msgd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     31\u001B[0m nlp\u001B[38;5;241m.\u001B[39mto_disk(output_dir)\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/language.py:1155\u001B[0m, in \u001B[0;36mLanguage.update\u001B[0;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001B[0m\n\u001B[1;32m   1152\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m name, proc \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpipeline:\n\u001B[1;32m   1153\u001B[0m     \u001B[38;5;66;03m# ignore statements are used here because mypy ignores hasattr\u001B[39;00m\n\u001B[1;32m   1154\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m exclude \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(proc, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mupdate\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1155\u001B[0m         \u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mupdate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msgd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlosses\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlosses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcomponent_cfg\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m   1156\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sgd \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m   1157\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m   1158\u001B[0m             name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m exclude\n\u001B[1;32m   1159\u001B[0m             \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(proc, ty\u001B[38;5;241m.\u001B[39mTrainableComponent)\n\u001B[1;32m   1160\u001B[0m             \u001B[38;5;129;01mand\u001B[39;00m proc\u001B[38;5;241m.\u001B[39mis_trainable\n\u001B[1;32m   1161\u001B[0m             \u001B[38;5;129;01mand\u001B[39;00m proc\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m   1162\u001B[0m         ):\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/pipeline/transition_parser.pyx:405\u001B[0m, in \u001B[0;36mspacy.pipeline.transition_parser.Parser.update\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/model.py:309\u001B[0m, in \u001B[0;36mModel.begin_update\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbegin_update\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable[[OutT], InT]]:\n\u001B[1;32m    303\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Run the model over a batch of data, returning the output and a\u001B[39;00m\n\u001B[1;32m    304\u001B[0m \u001B[38;5;124;03m    callback to complete the backward pass. A tuple (Y, finish_update),\u001B[39;00m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;124;03m    where Y is a batch of output data, and finish_update is a callback that\u001B[39;00m\n\u001B[1;32m    306\u001B[0m \u001B[38;5;124;03m    takes the gradient with respect to the output and an optimizer function,\u001B[39;00m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;124;03m    and returns the gradient with respect to the input.\u001B[39;00m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 309\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/ml/tb_framework.py:33\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(model, X, is_train):\n\u001B[0;32m---> 33\u001B[0m     step_model \u001B[38;5;241m=\u001B[39m \u001B[43mParserStepModel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     34\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     35\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     36\u001B[0m \u001B[43m        \u001B[49m\u001B[43munseen_classes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43munseen_classes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     37\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     38\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_upper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mhas_upper\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m step_model, step_model\u001B[38;5;241m.\u001B[39mfinish_steps\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/ml/parser_model.pyx:213\u001B[0m, in \u001B[0;36mspacy.ml.parser_model.ParserStepModel.__init__\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    289\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/layers/chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    289\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/layers/chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "    \u001B[0;31m[... skipping similar frames: Model.__call__ at line 291 (1 times)]\u001B[0m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/layers/chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    289\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/layers/with_array.py:37\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, Xseq, is_train)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\n\u001B[1;32m     34\u001B[0m     model: Model[SeqT, SeqT], Xseq: SeqT, is_train: \u001B[38;5;28mbool\u001B[39m\n\u001B[1;32m     35\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[SeqT, Callable]:\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(Xseq, Ragged):\n\u001B[0;32m---> 37\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m cast(Tuple[SeqT, Callable], \u001B[43m_ragged_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXseq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(Xseq, Padded):\n\u001B[1;32m     39\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m cast(Tuple[SeqT, Callable], _padded_forward(model, Xseq, is_train))\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/layers/with_array.py:92\u001B[0m, in \u001B[0;36m_ragged_forward\u001B[0;34m(model, Xr, is_train)\u001B[0m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_ragged_forward\u001B[39m(\n\u001B[1;32m     89\u001B[0m     model: Model[SeqT, SeqT], Xr: Ragged, is_train: \u001B[38;5;28mbool\u001B[39m\n\u001B[1;32m     90\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Ragged, Callable]:\n\u001B[1;32m     91\u001B[0m     layer: Model[ArrayXd, ArrayXd] \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m---> 92\u001B[0m     Y, get_dX \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataXd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackprop\u001B[39m(dYr: Ragged) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Ragged:\n\u001B[1;32m     95\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m Ragged(get_dX(dYr\u001B[38;5;241m.\u001B[39mdataXd), dYr\u001B[38;5;241m.\u001B[39mlengths)\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    289\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/layers/chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    289\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/layers/chain.py:55\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     53\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 55\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     57\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/model.py:291\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    289\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/thinc/layers/maxout.py:53\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     51\u001B[0m W \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mget_param(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     52\u001B[0m W \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mreshape2f(W, nO \u001B[38;5;241m*\u001B[39m nP, nI)\n\u001B[0;32m---> 53\u001B[0m Y \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgemm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrans2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     54\u001B[0m Y \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mreshape1f(b, nO \u001B[38;5;241m*\u001B[39m nP)\n\u001B[1;32m     55\u001B[0m Z \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mreshape3f(Y, Y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], nO, nP)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# train the first model on echr data\n",
    "import json\n",
    "from spacy.training.example import Example\n",
    "from collections import Counter\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\", enable=\"ner\")\n",
    "ner = nlp.get_pipe('ner')\n",
    "\n",
    "# from GH https://github.com/explosion/spaCy/issues/7161\n",
    "output_dir = \"../../data/models/spacy/output\"\n",
    "\n",
    "with open('../../data/annotated/echr_train_spacy.jsonl', \"r\", encoding=\"utf-8\") as f1:\n",
    "    train = json.load(f1)\n",
    "\n",
    "    # fetch and add labels\n",
    "    count_per_entity_new = Counter()\n",
    "    for _, annotations in train:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "           count_per_entity_new[ent[2]] +=1\n",
    "\n",
    "    for k in count_per_entity_new:\n",
    "        ner.add_label(k)\n",
    "\n",
    "optimizer = nlp.create_optimizer()\n",
    "for itn in range(2):\n",
    "    for raw_text,entity_offsets in train:\n",
    "        doc = nlp.make_doc(raw_text)\n",
    "        example = Example.from_dict(doc,entity_offsets)\n",
    "        nlp.update([example],sgd=optimizer)\n",
    "\n",
    "nlp.to_disk(output_dir)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T21:27:50.745820Z",
     "start_time": "2023-07-23T21:27:50.744616Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;4mℹ Using CPU\u001B[0m\r\n",
      "\u001B[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001B[0m\r\n",
      "\u001B[1m\r\n",
      "================================== Results ==================================\u001B[0m\r\n",
      "\r\n",
      "TOK     100.00\r\n",
      "NER P   29.27 \r\n",
      "NER R   39.50 \r\n",
      "NER F   33.63 \r\n",
      "SPEED   22339 \r\n",
      "\r\n",
      "\u001B[1m\r\n",
      "=============================== NER (per type) ===============================\u001B[0m\r\n",
      "\r\n",
      "                  P       R       F\r\n",
      "CARDINAL       0.00    0.00    0.00\r\n",
      "GPE            0.68    0.36    0.48\r\n",
      "ORG            9.32   10.29    9.78\r\n",
      "LAW            0.00    0.00    0.00\r\n",
      "NORP           0.00    0.00    0.00\r\n",
      "PERSON        18.95   20.78   19.82\r\n",
      "DATE          89.70   82.87   86.15\r\n",
      "LOC            0.00    0.00    0.00\r\n",
      "PRODUCT        0.00    0.00    0.00\r\n",
      "ORDINAL        0.00    0.00    0.00\r\n",
      "DEM            0.00    0.00    0.00\r\n",
      "TIME           0.00    0.00    0.00\r\n",
      "QUANTITY       0.00    0.00    0.00\r\n",
      "MONEY          0.00    0.00    0.00\r\n",
      "PERCENT        0.00    0.00    0.00\r\n",
      "LANGUAGE       0.00    0.00    0.00\r\n",
      "WORK_OF_ART    0.00    0.00    0.00\r\n",
      "FAC            0.00    0.00    0.00\r\n",
      "EVENT          0.00    0.00    0.00\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# testing the model\n",
    "!python -m spacy benchmark accuracy \"../../../data/models/spacy/output\" \"../../../data/annotated/dev.spacy\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T22:40:40.642677Z",
     "start_time": "2023-07-22T22:40:29.485473Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"30-Jan 2021 WORK EXPERIENCE Technology Consultant ...\" with entities \"[[47, 58, 'DATE'], [97, 109, 'ORG'], [110, 133, 'O...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"CRM Sales ( CRM 7.01, CRM 7.02, CRM 7.03) -Feb '20...\" with entities \"[[19, 23, 'CARDINAL'], [29, 33, 'CARDINAL'], [51, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Monitoring Dashboards setup using kibana.\" with entities \"[[37, 43, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Post handling the issue we were updating the MTTR ...\" with entities \"[[48, 52, 'ORG'], [57, 64, 'DATE']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Karizma Order Manager & Karizma Order System ORACL...\" with entities \"[[180, 233, 'ORG'], [234, 244, 'DATE']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Intimated the contract employees of AGL for repair...\" with entities \"[[3, 12, 'ORG'], [39, 42, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"To ensure that finished end document meets the cli...\" with entities \"[[58, 61, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Sanity testing on different environments • Perform...\" with entities \"[[542, 585, 'ORG'], [586, 590, 'DATE'], [621, 689,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Feb 2013 to Oct 2014 Designation: Senior Technical...\" with entities \"[[11, 19, 'DATE'], [75, 88, 'ORG'], [93, 98, 'ORG'...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Working in Microsoft Commercial Technical Support ...\" with entities \"[[96, 134, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Work closely with Infrastructure Teams to setup/ma...\" with entities \"[[21, 41, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Dayal Computers: - Working as a Technical Head 9th...\" with entities \"[[50, 53, 'ORDINAL'], [54, 66, 'DATE'], [70, 85, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Windows, Solaris ● Languages: Python, Core Java, S...\" with entities \"[[99, 108, 'PERSON'], [110, 113, 'ORG'], [132, 145...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Microsoft Rewards Data Insights:\" with entities \"[[3, 12, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Awarded as best Nesting Executive of the month EDU...\" with entities \"[[66, 83, 'ORG'], [87, 96, 'DATE'], [107, 170, 'OR...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Testing, Protractor, Selenium Webdriver, Automatio...\" with entities \"[[86, 104, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Project Title FINACLE INDUSTRY BANKING CLIENT Univ...\" with entities \"[[80, 106, 'ORG'], [107, 119, 'DATE'], [123, 131, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"INTERLINK Information Systems Pvt. Ltd: - Working ...\" with entities \"[[3, 52, 'ORG'], [82, 120, 'ORG'], [121, 139, 'DAT...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Delivery of team statistics, quality and productiv...\" with entities \"[[115, 122, 'DATE']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"An innovative Saraswati College Of Compilation Com...\" with entities \"[[119, 161, 'ORG'], [205, 206, 'CARDINAL'], [262, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"https://www.indeed.com/r/Shaheen-Unissa/c54e7a04da...\" with entities \"[[27, 124, 'PERSON']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"PwC Application Support ➢ Client: PricewaterhouseC...\" with entities \"[[3, 35, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"to Present Currently working in Global Standards I...\" with entities \"[[69, 85, 'ORG'], [99, 102, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Book orders for customers as per Cisco's booking p...\" with entities \"[[36, 41, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Member Technical Staff - Automation & Testing Cisc...\" with entities \"[[236, 249, 'ORG'], [252, 264, 'DATE'], [303, 316,...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Clinician is a complete healthcare solution for an...\" with entities \"[[10, 19, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Project Details Doodle Web (As Senior Systems Engi...\" with entities \"[[75, 92, 'ORG'], [94, 126, 'ORG'], [157, 184, 'OR...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Pal Business Systems: - Working as a Senior Engine...\" with entities \"[[3, 23, 'ORG'], [56, 71, 'DATE'], [75, 78, 'ORDIN...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Support departments in complying with ISO Quality ...\" with entities \"[[41, 63, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Providing the KPI report for the change process.\" with entities \"[[18, 21, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"• AADHAR (RFID) Card Based Voting Machine EDUCATIO...\" with entities \"[[44, 50, 'PERSON'], [52, 56, 'ORG'], [117, 121, '...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Understand the AS-IS process and develop to- Be de...\" with entities \"[[203, 227, 'ORG'], [236, 237, 'CARDINAL'], [246, ...\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Continuous Integration and deployment, maintaining...\" with entities \"[[148, 159, 'ORG']]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "# step 2\n",
    "# ref: https://github.com/explosion/spaCy/discussions/10041\n",
    "\n",
    "with open('../../data/annotated/rehearse_silver_sent_spacy.jsonl', \"r\") as f2:\n",
    "    rehearse = json.load(f2)\n",
    "\n",
    "\n",
    "    # fetch and add labels\n",
    "    count_per_entity_new = Counter()\n",
    "    for _, annotations in rehearse:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "           count_per_entity_new[ent[2]] +=1\n",
    "\n",
    "    for k in count_per_entity_new:\n",
    "        ner.add_label(k)\n",
    "\n",
    "    nlp_incremental_try = spacy.load(\"../../data/models/spacy/md/model-last\")\n",
    "    ner = nlp_incremental_try.get_pipe('ner')\n",
    "\n",
    "# '''\n",
    "# Make a \"rehearsal\" update to the models in the pipeline, to prevent forgetting. Rehearsal updates run an initial copy of the model over some data, and update the model so its current predictions are more like the initial ones. This is useful for keeping a pretrained model on-track, even if you're updating it with a smaller set of examples.\n",
    "#\n",
    "# rehearsal, collect samples of text you want the models to retain performance on, and call nlp.rehearse() with a batch of Example objects.\n",
    "# raw_batch = [Example.from_dict(nlp.make_doc(text), {}) for text in next(raw_text_batches)]\n",
    "# '''\n",
    "# # https://spacy.io/api/pipe#rehearse\n",
    "#\n",
    "    optimizer = nlp_incremental_try.resume_training()\n",
    "    for itn in range(20):\n",
    "        random.shuffle(rehearse)\n",
    "        for raw_text, entity_offsets in rehearse:\n",
    "            doc = nlp_incremental_try.make_doc(raw_text)\n",
    "            example = Example.from_dict(doc,entity_offsets)\n",
    "            nlp_incremental_try.rehearse([example],sgd=optimizer)\n",
    "    nlp.to_disk(\"../../data/models/spacy/rehearse\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T22:44:15.555757Z",
     "start_time": "2023-07-23T22:22:13.572354Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;4mℹ Using CPU\u001B[0m\r\n",
      "\u001B[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001B[0m\r\n",
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/training/corpus.py:102: UserWarning: [W090] Could not locate any .spacy files in path '../../data/annotated/rehearse_silver_sent_test.jsonl'.\r\n",
      "  warnings.warn(Warnings.W090.format(path=orig_path, format=file_type))\r\n",
      "\u001B[1m\r\n",
      "================================== Results ==================================\u001B[0m\r\n",
      "\r\n",
      "TOK     -\r\n",
      "NER P   -\r\n",
      "NER R   -\r\n",
      "NER F   -\r\n",
      "SPEED   0\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy benchmark accuracy \"../../data/models/spacy/rehearse\" \"../../data/annotated/rehearse_silver_sent_test.jsonl\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T22:58:35.389280Z",
     "start_time": "2023-07-23T22:58:30.417348Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = [\n",
    "    ('Who is Kofi Annan?',{\n",
    "    'entities':[(7,18,'PERSON')]\n",
    "    }),\n",
    "    ('Who is Steve Jobs?',{\n",
    "    'entities':[(7,17,'PERSON')]\n",
    "    }),\n",
    "    ('I like London and Berlin.',{\n",
    "    'entities':[(7,13,'LOC'),(18,24,'LOC')]\n",
    "    })\n",
    "]\n",
    "print(type(TRAIN_DATA))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-23T03:49:08.360047Z",
     "start_time": "2023-07-23T03:49:08.309777Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
