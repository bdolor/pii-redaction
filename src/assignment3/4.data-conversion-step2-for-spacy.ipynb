{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Conversion\n",
    "## JSON to SpaCy binary\n",
    "Takes an annotated dataset (JSON) using Presidio Research (based on SpaCy model) which combines synthetically generated PII with sentence templates and coverts them to SpaCy binary for step 2 in Incremental Training\n",
    "\n",
    "modified from the original: Brad Payne\n",
    "modifications: creates Spacy binary files\n",
    "original file: https://github.com/NorskRegnesentral/text-anonymization-benchmark/blob/master/longformer_experiments/data_manipulation.py\n",
    "original author: Norsk Regnesentral\n",
    "license: MIT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-26T21:13:49.460735Z",
     "start_time": "2023-07-26T21:13:45.346574Z"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import json\n",
    "\n",
    "with open('../../data/annotated/train_step2.json', \"r\", encoding=\"utf-8\") as f1, open('../../data/annotated/test_step2.json', \"r\", encoding=\"utf-8\") as f3:\n",
    "\n",
    "    train = json.load(f1)\n",
    "    test = json.load(f3)\n",
    "\n",
    "    # TEST, aka DEV in Spacy-land\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    db = DocBin()\n",
    "    for data in test:\n",
    "        doc = nlp(data['full_text'])\n",
    "        ents = []\n",
    "        for annotation in data['spans']:\n",
    "            span = doc.char_span(annotation['start_position'], annotation['end_position'], label=annotation['entity_type'], alignment_mode=\"contract\")\n",
    "            if span is not None:\n",
    "                ents.append(span)\n",
    "        if ents is not None:\n",
    "            doc.ents = spacy.util.filter_spans(ents)\n",
    "        db.add(doc)\n",
    "\n",
    "    db.to_disk(\"../../data/annotated/dev_step2.spacy\")\n",
    "    del db, nlp\n",
    "\n",
    "    # TRAIN\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    db = DocBin()\n",
    "    for data in train:\n",
    "        doc = nlp(data['full_text'])\n",
    "        ents = []\n",
    "        for annotation in data['spans']:\n",
    "            span = doc.char_span(annotation['start_position'], annotation['end_position'], label=annotation['entity_type'], alignment_mode=\"contract\")\n",
    "            if span is not None:\n",
    "                ents.append(span)\n",
    "        if ents is not None:\n",
    "            doc.ents = spacy.util.filter_spans(ents)\n",
    "        db.add(doc)\n",
    "\n",
    "    db.to_disk(\"../../data/annotated/train_step2.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
