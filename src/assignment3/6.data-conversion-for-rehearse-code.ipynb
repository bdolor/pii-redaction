{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data Conversion for Rehearsal\n",
    "## Creates a 'silver' annotated dataset for the rehearsal process\n",
    "So that Catastrophic Forgetting can be avoided, a dataset with the entities from the original model can be passed to the rehearse function in the training routine."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# extract text from resumes, output to jsonl\n",
    "\n",
    "'''\n",
    "Make a \"rehearsal\" update to the models in the pipeline, to prevent forgetting. Rehearsal updates run an initial copy of the model over some data, and update the model so its current predictions are more like the initial ones. This is useful for keeping a pretrained model on-track, even if you're updating it with a smaller set of examples.\n",
    "'''\n",
    "\n",
    "import re\n",
    "import json\n",
    "import srsly\n",
    "\n",
    "# avoids JSONDecodeError due to malformed json file\n",
    "data = [json.loads(line)\n",
    "        for line in open(\"../../data/annotated/resumedata.json\", \"r\", encoding=\"utf-8\")]\n",
    "\n",
    "content = []\n",
    "for k in data:\n",
    "    dct = {\n",
    "        \"text\": re.sub(r\"\\s+\", \" \", k[\"content\"])\n",
    "    }\n",
    "    content.append(dct)\n",
    "\n",
    "srsly.write_json(\"../../data/resume.jsonl\", content)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T21:46:23.180449Z",
     "start_time": "2023-07-26T21:46:23.080728Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Generation\n",
    "## Take raw Resume data, break it up into sentences, and format it to SpaCy compatible JSON"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import srsly\n",
    "import json\n",
    "import spacy\n",
    "activated = spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "with open(\"../../data/resume.jsonl\", \"r\", encoding=\"utf-8\") as f1:\n",
    "    resume = json.load(f1)\n",
    "\n",
    "    sent_parse = []\n",
    "    for k in resume:\n",
    "        doc = nlp(k[\"text\"])\n",
    "        for s in doc.sents:\n",
    "            if len(s) > 2:\n",
    "                try:\n",
    "                    # f = re.sub(r\"\\s\\-\\s+\", \"\", s)\n",
    "                    sent_parse.append({'text': f\"{s}\"})\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "\n",
    "srsly.write_json(\"../../data/resume_sentences_parser.jsonl\", sent_parse)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T21:47:09.030621Z",
     "start_time": "2023-07-26T21:46:51.068065Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Generation\n",
    "## 'Silver' Annotated dataset\n",
    "Using a SpaCy model, run the resume data over it to produce a 'silver' annotated dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "# create a silver annotated dataset with sentences (train/test)\n",
    "\n",
    "'''\n",
    "Rehearsal updates run an initial copy of the model over some data\n",
    "'''\n",
    "activated = spacy.prefer_gpu()\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "with open(\"../../data/resume_sentences_parser.jsonl\", \"r\", encoding=\"utf-8\") as f1:\n",
    "    resume = json.load(f1)\n",
    "\n",
    "    limit = 0.2\n",
    "    train = list()\n",
    "    test = list()\n",
    "    for k in resume:\n",
    "        doc = nlp(k[\"text\"])\n",
    "        for sent in doc.sents:\n",
    "            labels = list()\n",
    "            for e in sent.ents:\n",
    "                labels.append([e.start_char, e.end_char, e.label_])\n",
    "            if labels:\n",
    "                spacy_entry = (sent.text, {\"entities\": labels})\n",
    "                if random.uniform(0, 1) > limit:\n",
    "                    train.append(spacy_entry)\n",
    "                else:\n",
    "                    test.append(spacy_entry)\n",
    "\n",
    "    srsly.write_json(\"../../data/annotated/rehearse_silver_sent_train.jsonl\", train)\n",
    "    srsly.write_json(\"../../data/annotated/rehearse_silver_sent_test.jsonl\", test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T21:48:53.794994Z",
     "start_time": "2023-07-26T21:48:21.664780Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# convert ECHR training data (from SpaCy binary to JSONL) so that we can train a spacy model using code (and not CLI)\n",
    "\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "doc_bin = DocBin().from_disk(\"../../data/annotated/train.spacy\")\n",
    "examples = []\n",
    "for doc in doc_bin.get_docs(nlp.vocab):\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.start_char, ent.end_char, ent.label_))\n",
    "\n",
    "    spacy_entry = (doc.text, {\"entities\": entities})\n",
    "    examples.append(spacy_entry)\n",
    "\n",
    "    srsly.write_json(\"../../data/annotated/echr_train_spacy.jsonl\", examples)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# convert ECHR testing data (from SpaCy binary to JSONL) so that we can test a spacy model using code (and not CLI)\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "doc_bin = DocBin().from_disk(\"../../data/annotated/dev.spacy\")\n",
    "examples = []\n",
    "for doc in doc_bin.get_docs(nlp.vocab):\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append((ent.start_char, ent.end_char, ent.label_))\n",
    "\n",
    "    spacy_entry = (doc.text, {\"entities\": entities})\n",
    "    examples.append(spacy_entry)\n",
    "\n",
    "    srsly.write_json(\"../../data/annotated/echr_dev_spacy.jsonl\", examples)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T21:37:45.647739Z",
     "start_time": "2023-07-26T21:37:44.662108Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "### Converting Resume data in JSON to SpaCy binary\n",
    "In order to perform evaluations (benchmark accuracy) and run training using CLI, data needs to be converted to the SpaCy (version 3) binary format (*.spacy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# takes resume train and test JSON to convert it into SpaCy binary files\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "import json\n",
    "\n",
    "with open('../../data/annotated/rehearse_silver_sent_train.jsonl', \"r\", encoding=\"utf-8\") as f1, open('../../data/annotated/rehearse_silver_sent_test.jsonl', \"r\", encoding=\"utf-8\") as f2:\n",
    "\n",
    "    train = json.load(f1)\n",
    "    test = json.load(f2)\n",
    "\n",
    "    # TRAIN\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    db = DocBin()\n",
    "    for text, annotations in train:\n",
    "        doc = nlp(text)\n",
    "        ents = []\n",
    "        for start, end, label in annotations.get(\"entities\"):\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span:\n",
    "                ents.append(span)\n",
    "        if ents:\n",
    "            doc.ents = ents\n",
    "            db.add(doc)\n",
    "    db.to_disk(\"../../data/annotated/train_silver_resume.spacy\")\n",
    "    del db, nlp\n",
    "\n",
    "    # TEST\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    db = DocBin()\n",
    "    for text, annotations in test:\n",
    "        doc = nlp(text)\n",
    "        ents = []\n",
    "        for start, end, label in annotations.get(\"entities\"):\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            if span:\n",
    "                ents.append(span)\n",
    "        if ents:\n",
    "            doc.ents = ents\n",
    "            db.add(doc)\n",
    "\n",
    "    db.to_disk(\"../../data/annotated/test_silver_resume.spacy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T22:04:51.697837Z",
     "start_time": "2023-07-26T22:04:50.015378Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[38;5;4mâ„¹ Using GPU: 0\u001B[0m\r\n",
      "\u001B[1m\r\n",
      "================================== Results ==================================\u001B[0m\r\n",
      "\r\n",
      "TOK      100.00\r\n",
      "TAG      -     \r\n",
      "POS      -     \r\n",
      "MORPH    -     \r\n",
      "LEMMA    -     \r\n",
      "UAS      -     \r\n",
      "LAS      -     \r\n",
      "NER P    99.93 \r\n",
      "NER R    99.96 \r\n",
      "NER F    99.95 \r\n",
      "SENT P   -     \r\n",
      "SENT R   -     \r\n",
      "SENT F   -     \r\n",
      "SPEED    8268  \r\n",
      "\r\n",
      "\u001B[1m\r\n",
      "=============================== NER (per type) ===============================\u001B[0m\r\n",
      "\r\n",
      "                   P        R        F\r\n",
      "ORG            99.93    99.93    99.93\r\n",
      "PRODUCT       100.00   100.00   100.00\r\n",
      "PERSON        100.00   100.00   100.00\r\n",
      "CARDINAL      100.00   100.00   100.00\r\n",
      "GPE           100.00   100.00   100.00\r\n",
      "DATE           99.78   100.00    99.89\r\n",
      "WORK_OF_ART   100.00   100.00   100.00\r\n",
      "NORP          100.00   100.00   100.00\r\n",
      "LOC           100.00   100.00   100.00\r\n",
      "LAW           100.00   100.00   100.00\r\n",
      "LANGUAGE      100.00   100.00   100.00\r\n",
      "FAC           100.00   100.00   100.00\r\n",
      "ORDINAL       100.00   100.00   100.00\r\n",
      "QUANTITY      100.00   100.00   100.00\r\n",
      "EVENT         100.00   100.00   100.00\r\n",
      "MONEY         100.00   100.00   100.00\r\n",
      "PERCENT       100.00   100.00   100.00\r\n",
      "TIME          100.00   100.00   100.00\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# the same model was used to build the silver annotated dataset so no surprise it performs well!\n",
    "# sanity test to ensure that it works\n",
    "!python -m spacy benchmark accuracy --gpu-id=0 \"en_core_web_md\" \"../../data/annotated/test_silver_resume.spacy\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-26T22:05:15.123210Z",
     "start_time": "2023-07-26T22:05:05.891747Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
