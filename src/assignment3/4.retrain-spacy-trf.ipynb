{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-22T05:47:32.115980Z",
     "start_time": "2023-07-22T05:47:27.721389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (3.5.3)\r\n",
      "Collecting spacy\r\n",
      "  Using cached spacy-3.6.0-cp310-cp310-macosx_10_9_x86_64.whl (6.9 MB)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (1.0.4)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (1.0.9)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (2.0.7)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (3.0.8)\r\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (8.1.10)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (1.1.2)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (2.4.6)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (2.0.8)\r\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (0.7.0)\r\n",
      "Requirement already satisfied: pathy>=0.10.0 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (0.10.1)\r\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (6.3.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (4.65.0)\r\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (1.23.5)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (2.31.0)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (1.10.9)\r\n",
      "Requirement already satisfied: jinja2 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (3.1.2)\r\n",
      "Requirement already satisfied: setuptools in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (67.8.0)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (23.1)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from spacy) (3.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.6.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.5.7)\r\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\r\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\r\n",
      "Installing collected packages: spacy\r\n",
      "  Attempting uninstall: spacy\r\n",
      "    Found existing installation: spacy 3.5.3\r\n",
      "    Uninstalling spacy-3.5.3:\r\n",
      "      Successfully uninstalled spacy-3.5.3\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "en-core-web-lg 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.6.0 which is incompatible.\r\n",
      "en-core-web-md 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.6.0 which is incompatible.\r\n",
      "en-core-web-sm 3.5.0 requires spacy<3.6.0,>=3.5.0, but you have spacy 3.6.0 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed spacy-3.6.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m23.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.2\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "#!python -m spacy download en_core_web_trf\n",
    "!pip install --upgrade spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "ConfigValidationError",
     "evalue": "\n\nConfig validation error\ntagger -> label_smoothing\textra fields not permitted\n{'nlp': <spacy.lang.en.English object at 0x134c0ac20>, 'name': 'tagger', 'label_smoothing': 0.0, 'model': {'@architectures': 'spacy.Tagger.v2', 'nO': None, 'normalize': False, 'tok2vec': {'@architectures': 'spacy-transformers.TransformerListener.v1', 'grad_factor': 1.0, 'upstream': 'transformer', 'pooling': {'@layers': 'reduce_mean.v1'}}}, 'neg_prefix': '!', 'overwrite': False, 'scorer': {'@scorers': 'spacy.tagger_scorer.v1'}, '@factories': 'tagger'}",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConfigValidationError\u001B[0m                     Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mspacy_transformers\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m nlp \u001B[38;5;241m=\u001B[39m \u001B[43mspacy\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43men_core_web_trf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m text \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'''\u001B[39m\u001B[38;5;124mSIDDHARTH RAGHUVANSHI                                Roll No. 06CS3025                                            DOB: 08/08/1988\u001B[39m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;124mEmail: siddharth.iitkharagpur@gmail.com                                                                                          Mobile No.:   +91 9932584135\u001B[39m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;124mDegree/Certificate\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     91\u001B[0m \u001B[38;5;124m  Member of Silver winning team in inter hall OPENSOFT Competition in the session 2007-08.\u001B[39m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;124m  National Sports Organization: Among Top 30 students in Lawn Tennis Team at IIT Kharagpur’06. \u001B[39m\u001B[38;5;124m'''\u001B[39m]\n\u001B[1;32m     94\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m nlp\u001B[38;5;241m.\u001B[39mpipe(text):\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/__init__.py:54\u001B[0m, in \u001B[0;36mload\u001B[0;34m(name, vocab, disable, enable, exclude, config)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(\n\u001B[1;32m     31\u001B[0m     name: Union[\u001B[38;5;28mstr\u001B[39m, Path],\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;241m*\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     37\u001B[0m     config: Union[Dict[\u001B[38;5;28mstr\u001B[39m, Any], Config] \u001B[38;5;241m=\u001B[39m util\u001B[38;5;241m.\u001B[39mSimpleFrozenDict(),\n\u001B[1;32m     38\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Language:\n\u001B[1;32m     39\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001B[39;00m\n\u001B[1;32m     40\u001B[0m \n\u001B[1;32m     41\u001B[0m \u001B[38;5;124;03m    name (str): Package name or model path.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001B[39;00m\n\u001B[1;32m     53\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 54\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mutil\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdisable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     58\u001B[0m \u001B[43m        \u001B[49m\u001B[43menable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     59\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     60\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/util.py:442\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(name, vocab, disable, enable, exclude, config)\u001B[0m\n\u001B[1;32m    440\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get_lang_class(name\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblank:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m))()\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_package(name):  \u001B[38;5;66;03m# installed as package\u001B[39;00m\n\u001B[0;32m--> 442\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_model_from_package\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m Path(name)\u001B[38;5;241m.\u001B[39mexists():  \u001B[38;5;66;03m# path to model data directory\u001B[39;00m\n\u001B[1;32m    444\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m load_model_from_path(Path(name), \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/util.py:478\u001B[0m, in \u001B[0;36mload_model_from_package\u001B[0;34m(name, vocab, disable, enable, exclude, config)\u001B[0m\n\u001B[1;32m    461\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Load a model from an installed package.\u001B[39;00m\n\u001B[1;32m    462\u001B[0m \n\u001B[1;32m    463\u001B[0m \u001B[38;5;124;03mname (str): The package name.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    475\u001B[0m \u001B[38;5;124;03mRETURNS (Language): The loaded nlp object.\u001B[39;00m\n\u001B[1;32m    476\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28mcls\u001B[39m \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mimport_module(name)\n\u001B[0;32m--> 478\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdisable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/en_core_web_trf/__init__.py:10\u001B[0m, in \u001B[0;36mload\u001B[0;34m(**overrides)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39moverrides):\n\u001B[0;32m---> 10\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_model_from_init_py\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;18;43m__file__\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43moverrides\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/util.py:659\u001B[0m, in \u001B[0;36mload_model_from_init_py\u001B[0;34m(init_file, vocab, disable, enable, exclude, config)\u001B[0m\n\u001B[1;32m    657\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m model_path\u001B[38;5;241m.\u001B[39mexists():\n\u001B[1;32m    658\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mIOError\u001B[39;00m(Errors\u001B[38;5;241m.\u001B[39mE052\u001B[38;5;241m.\u001B[39mformat(path\u001B[38;5;241m=\u001B[39mdata_path))\n\u001B[0;32m--> 659\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mload_model_from_path\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    660\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    661\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    662\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    663\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdisable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    664\u001B[0m \u001B[43m    \u001B[49m\u001B[43menable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    665\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    666\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    667\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/util.py:516\u001B[0m, in \u001B[0;36mload_model_from_path\u001B[0;34m(model_path, meta, vocab, disable, enable, exclude, config)\u001B[0m\n\u001B[1;32m    514\u001B[0m overrides \u001B[38;5;241m=\u001B[39m dict_to_dot(config)\n\u001B[1;32m    515\u001B[0m config \u001B[38;5;241m=\u001B[39m load_config(config_path, overrides\u001B[38;5;241m=\u001B[39moverrides)\n\u001B[0;32m--> 516\u001B[0m nlp \u001B[38;5;241m=\u001B[39m \u001B[43mload_model_from_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdisable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m    \u001B[49m\u001B[43menable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m nlp\u001B[38;5;241m.\u001B[39mfrom_disk(model_path, exclude\u001B[38;5;241m=\u001B[39mexclude, overrides\u001B[38;5;241m=\u001B[39moverrides)\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/util.py:564\u001B[0m, in \u001B[0;36mload_model_from_config\u001B[0;34m(config, meta, vocab, disable, enable, exclude, auto_fill, validate)\u001B[0m\n\u001B[1;32m    561\u001B[0m \u001B[38;5;66;03m# This will automatically handle all codes registered via the languages\u001B[39;00m\n\u001B[1;32m    562\u001B[0m \u001B[38;5;66;03m# registry, including custom subclasses provided via entry points\u001B[39;00m\n\u001B[1;32m    563\u001B[0m lang_cls \u001B[38;5;241m=\u001B[39m get_lang_class(nlp_config[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlang\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[0;32m--> 564\u001B[0m nlp \u001B[38;5;241m=\u001B[39m \u001B[43mlang_cls\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_config\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    565\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    566\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    567\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdisable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdisable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    568\u001B[0m \u001B[43m    \u001B[49m\u001B[43menable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    569\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexclude\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexclude\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    570\u001B[0m \u001B[43m    \u001B[49m\u001B[43mauto_fill\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mauto_fill\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    571\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    572\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    573\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    574\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m nlp\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/language.py:1803\u001B[0m, in \u001B[0;36mLanguage.from_config\u001B[0;34m(cls, config, vocab, disable, enable, exclude, meta, auto_fill, validate)\u001B[0m\n\u001B[1;32m   1800\u001B[0m     factory \u001B[38;5;241m=\u001B[39m pipe_cfg\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfactory\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   1801\u001B[0m     \u001B[38;5;66;03m# The pipe name (key in the config) here is the unique name\u001B[39;00m\n\u001B[1;32m   1802\u001B[0m     \u001B[38;5;66;03m# of the component, not necessarily the factory\u001B[39;00m\n\u001B[0;32m-> 1803\u001B[0m     \u001B[43mnlp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_pipe\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1804\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfactory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1805\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpipe_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1806\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpipe_cfg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1807\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1808\u001B[0m \u001B[43m        \u001B[49m\u001B[43mraw_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mraw_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1809\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1810\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1811\u001B[0m     \u001B[38;5;66;03m# We need the sourced components to reference the same\u001B[39;00m\n\u001B[1;32m   1812\u001B[0m     \u001B[38;5;66;03m# vocab without modifying the current vocab state **AND**\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1817\u001B[0m     \u001B[38;5;66;03m# during deserialization, so they do not need any\u001B[39;00m\n\u001B[1;32m   1818\u001B[0m     \u001B[38;5;66;03m# additional handling.\u001B[39;00m\n\u001B[1;32m   1819\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m vocab_b \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/language.py:786\u001B[0m, in \u001B[0;36mLanguage.add_pipe\u001B[0;34m(self, factory_name, name, before, after, first, last, source, config, raw_config, validate)\u001B[0m\n\u001B[1;32m    782\u001B[0m     pipe_component, factory_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_pipe_from_source(\n\u001B[1;32m    783\u001B[0m         factory_name, source, name\u001B[38;5;241m=\u001B[39mname\n\u001B[1;32m    784\u001B[0m     )\n\u001B[1;32m    785\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 786\u001B[0m     pipe_component \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_pipe\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    787\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfactory_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[43m        \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    789\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m        \u001B[49m\u001B[43mraw_config\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mraw_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m        \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    793\u001B[0m pipe_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_pipe_index(before, after, first, last)\n\u001B[1;32m    794\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pipe_meta[name] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_factory_meta(factory_name)\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/language.py:679\u001B[0m, in \u001B[0;36mLanguage.create_pipe\u001B[0;34m(self, factory_name, name, config, raw_config, validate)\u001B[0m\n\u001B[1;32m    676\u001B[0m cfg \u001B[38;5;241m=\u001B[39m {factory_name: config}\n\u001B[1;32m    677\u001B[0m \u001B[38;5;66;03m# We're calling the internal _fill here to avoid constructing the\u001B[39;00m\n\u001B[1;32m    678\u001B[0m \u001B[38;5;66;03m# registered functions twice\u001B[39;00m\n\u001B[0;32m--> 679\u001B[0m resolved \u001B[38;5;241m=\u001B[39m \u001B[43mregistry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresolve\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    680\u001B[0m filled \u001B[38;5;241m=\u001B[39m registry\u001B[38;5;241m.\u001B[39mfill({\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcfg\u001B[39m\u001B[38;5;124m\"\u001B[39m: cfg[factory_name]}, validate\u001B[38;5;241m=\u001B[39mvalidate)[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcfg\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    681\u001B[0m filled \u001B[38;5;241m=\u001B[39m Config(filled)\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/confection/__init__.py:728\u001B[0m, in \u001B[0;36mregistry.resolve\u001B[0;34m(cls, config, schema, overrides, validate)\u001B[0m\n\u001B[1;32m    719\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    720\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mresolve\u001B[39m(\n\u001B[1;32m    721\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    726\u001B[0m     validate: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    727\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, Any]:\n\u001B[0;32m--> 728\u001B[0m     resolved, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    729\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moverrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverrides\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresolve\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m    730\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    731\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resolved\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/confection/__init__.py:777\u001B[0m, in \u001B[0;36mregistry._make\u001B[0;34m(cls, config, schema, overrides, resolve, validate)\u001B[0m\n\u001B[1;32m    775\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_interpolated:\n\u001B[1;32m    776\u001B[0m     config \u001B[38;5;241m=\u001B[39m Config(orig_config)\u001B[38;5;241m.\u001B[39minterpolate()\n\u001B[0;32m--> 777\u001B[0m filled, _, resolved \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fill\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    778\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mschema\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moverrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverrides\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mresolve\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresolve\u001B[49m\n\u001B[1;32m    779\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    780\u001B[0m filled \u001B[38;5;241m=\u001B[39m Config(filled, section_order\u001B[38;5;241m=\u001B[39msection_order)\n\u001B[1;32m    781\u001B[0m \u001B[38;5;66;03m# Check that overrides didn't include invalid properties not in config\u001B[39;00m\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/confection/__init__.py:832\u001B[0m, in \u001B[0;36mregistry._fill\u001B[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001B[0m\n\u001B[1;32m    830\u001B[0m     schema\u001B[38;5;241m.\u001B[39m__fields__[key] \u001B[38;5;241m=\u001B[39m copy_model_field(field, Any)\n\u001B[1;32m    831\u001B[0m promise_schema \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mmake_promise_schema(value, resolve\u001B[38;5;241m=\u001B[39mresolve)\n\u001B[0;32m--> 832\u001B[0m filled[key], validation[v_key], final[key] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fill\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpromise_schema\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresolve\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresolve\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    837\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparent\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkey_parent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    838\u001B[0m \u001B[43m    \u001B[49m\u001B[43moverrides\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moverrides\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    839\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    840\u001B[0m reg_name, func_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mget_constructor(final[key])\n\u001B[1;32m    841\u001B[0m args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mparse_args(final[key])\n",
      "File \u001B[0;32m~/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/confection/__init__.py:898\u001B[0m, in \u001B[0;36mregistry._fill\u001B[0;34m(cls, config, schema, validate, resolve, parent, overrides)\u001B[0m\n\u001B[1;32m    896\u001B[0m         result \u001B[38;5;241m=\u001B[39m schema\u001B[38;5;241m.\u001B[39mparse_obj(validation)\n\u001B[1;32m    897\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ValidationError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 898\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ConfigValidationError(\n\u001B[1;32m    899\u001B[0m             config\u001B[38;5;241m=\u001B[39mconfig, errors\u001B[38;5;241m=\u001B[39me\u001B[38;5;241m.\u001B[39merrors(), parent\u001B[38;5;241m=\u001B[39mparent\n\u001B[1;32m    900\u001B[0m         ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    901\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;66;03m# Same as parse_obj, but without validation\u001B[39;00m\n\u001B[1;32m    903\u001B[0m     result \u001B[38;5;241m=\u001B[39m schema\u001B[38;5;241m.\u001B[39mconstruct(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mvalidation)\n",
      "\u001B[0;31mConfigValidationError\u001B[0m: \n\nConfig validation error\ntagger -> label_smoothing\textra fields not permitted\n{'nlp': <spacy.lang.en.English object at 0x134c0ac20>, 'name': 'tagger', 'label_smoothing': 0.0, 'model': {'@architectures': 'spacy.Tagger.v2', 'nO': None, 'normalize': False, 'tok2vec': {'@architectures': 'spacy-transformers.TransformerListener.v1', 'grad_factor': 1.0, 'upstream': 'transformer', 'pooling': {'@layers': 'reduce_mean.v1'}}}, 'neg_prefix': '!', 'overwrite': False, 'scorer': {'@scorers': 'spacy.tagger_scorer.v1'}, '@factories': 'tagger'}"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import spacy_transformers\n",
    "import torch\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "\n",
    "text = ['''SIDDHARTH RAGHUVANSHI                                Roll No. 06CS3025                                            DOB: 08/08/1988\n",
    "Email: siddharth.iitkharagpur@gmail.com                                                                                          Mobile No.:   +91 9932584135\n",
    "Degree/Certificate\n",
    "Dual Degree[B. Tech (H) + M. Tech]\n",
    "(Computer Science & Engineering)\n",
    "Class XII:  C.B.S.E.\n",
    "Class X:   C.B.S.E.\n",
    "ACADEMIC ACHIEVEMENTS\n",
    "Institute/ School, City\n",
    "Indian Institute of Technology, Kharagpur\n",
    "Central Hindu School, Varanasi\n",
    "St. Atulanand Convent School, Varanasi\n",
    "CGPA/ %  Completion\n",
    "8.26/10\n",
    "86.0%\n",
    "90.8%\n",
    "2011\n",
    "2005\n",
    "2003\n",
    "Competitive\n",
    "Examinations\n",
    "  All India Rank 116 in AIEEE, 2006 among 470,000 students, State Rank 8 in Uttar Pradesh.\n",
    "  All India Rank 119 in 7th National Science Olympiad, 2005.\n",
    "  All India Rank 22 in All India Level Mathematics & Science Test organized by Central Institute  for\n",
    "Proficiency in English Language (CIPEL).\n",
    "Scholastic\n",
    "Achievements\n",
    "  National top 1% out of 26968 candidates appeared in National Standard Examination in Physics’05\n",
    "  Receiving CBSE Merit Scholarship for the past 4 years.\n",
    "ACADEMIC PROJECTS\n",
    "M. Tech Project                                                                                      IIT Kharagpur                                           May’10-Nov’10\n",
    "•\n",
    "•\n",
    "Studied the performance of text indexing algorithms on Hadoop MapReduce architecture.\n",
    "Future work includes implementing more efficient indexing and retrieval techniques in MapReduce for distributed parallel\n",
    "computing.\n",
    "B. Tech Project                                                                                        IIT Kharagpur                                           Aug’09-May’10\n",
    "  Developed a software with can handle all sorts of query related to geographical information extracted from maps.\n",
    "  Developed a client interface which can fetch data from different incompatible geospatial web services and make that data\n",
    "compatible for resolving queries.\n",
    "Integrated my framework engine with different underlying heterogeneous spatial databases.\n",
    "\n",
    "Static Instrumentation Of Java Programs                                          IIT Kharagpur                                                   May’08\n",
    "  Developed a program using Byte Code Engineering Library to do automated testing of java program at byte code level.\n",
    "WORK EXPERIENCE / INTERNSHIP\n",
    "Extreme Blue Internship Program                                                                   ISL, IBM, Pune, India                                       May’09 – July’09\n",
    "Business\n",
    "Perspective\n",
    "Technical\n",
    "Perspective\n",
    " Achievements\n",
    "  Conducted survey in Pune region on the current home delivery status of organized retails\n",
    "\n",
    "Proposed and implemented a solution on how to increase home delivery sales in order to compete with the\n",
    "localized general (kirana) stores\n",
    "\n",
    "Built an independent Home Delivery module on Java EE platform using open standards such as XML and\n",
    "Web Services\n",
    "Integrated the Home Delivery module with IBM WebSphere Commerce.\n",
    "\n",
    "  Received highest grade 10/10 in summer internship evaluation at IIT Kharagpur, 2009.\n",
    "RELEVANT COURSES TAKEN\n",
    "  Machine learning\n",
    "  Algorithms-I\n",
    "  Algorithms-II\n",
    "Information Retrieval\n",
    "\n",
    "  Distributed Systems\n",
    "\n",
    "Probability and Statistics\n",
    "POSITION OF RESPONSIBILITY\n",
    "\n",
    "Student coordinator of IIT Kharagpur Student Counselling Service.\n",
    "  Student member of team that conceptualized and publicized Counselling Centre in IIT Kharagpur after 5 successive suicides\n",
    "in the campus within a span of 6 months in between Feb’09 and Jul’09.\n",
    "  More than 100 students are counselled every month.\n",
    "  No mishaps in the campus as of Sep’10 after the establishment of the centre.\n",
    "  Went through Gate Keepers Training to identify behavioral change in a person.\n",
    "  Managed  the  systems  team  of  Bitwise-2010,  an  international  algorithmic  intensive  programming  contest  leading  to  the\n",
    "participation of 3000 teams across 75 countries.\n",
    "\n",
    "Family Sub-head of accommodation team in Spring Fest, 2008.\n",
    "  Head boy of my Senior Secondary School (Central Hindu School).\n",
    "e\n",
    "EXTRA CURRICULAR ACHIEVEMENTS\n",
    "  Member of Silver winning team in inter hall OPENSOFT Competition in the session 2007-08.\n",
    "  National Sports Organization: Among Top 30 students in Lawn Tennis Team at IIT Kharagpur’06. ''']\n",
    "\n",
    "for doc in nlp.pipe(text):\n",
    "    print([(ent.text, ent.label_) for ent in doc.ents])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-22T14:59:08.966957Z",
     "start_time": "2023-07-22T14:59:08.403937Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/bpayne/code/data-science/pii-redaction/venv/lib/python3.10/site-packages/spacy/util.py:887: UserWarning: [W095] Model 'en_core_web_trf' (3.6.1) was trained with spaCy v3.6 and may not be 100% compatible with the current version (3.5.3). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\r\n",
      "  warnings.warn(warn_msg)\r\n",
      "\u001B[38;5;1m✘ Config validation error\u001B[0m\r\n",
      "tagger -> label_smoothing\textra fields not permitted\r\n",
      "{'nlp': <spacy.lang.en.English object at 0x139bf6200>, 'name': 'tagger', 'label_smoothing': 0.0, 'model': {'@architectures': 'spacy.Tagger.v2', 'nO': None, 'normalize': False, 'tok2vec': {'@architectures': 'spacy-transformers.TransformerListener.v1', 'grad_factor': 1.0, 'upstream': 'transformer', 'pooling': {'@layers': 'reduce_mean.v1'}}}, 'neg_prefix': '!', 'overwrite': False, 'scorer': {'@scorers': 'spacy.tagger_scorer.v1'}, '@factories': 'tagger'}\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config config/base_config_trf.cfg config/config_trf.cfg"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-21T19:19:21.244472Z",
     "start_time": "2023-07-21T19:19:18.057367Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python -m spacy debug data config/config_trf.cfg"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python -m spacy train config/config_trf.cfg -o ../../data/models/spacy/trf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('./model-best')\n",
    "\n",
    "text = ['''SIDDHARTH RAGHUVANSHI                                Roll No. 06CS3025                                            DOB: 08/08/1988\n",
    "Email: siddharth.iitkharagpur@gmail.com                                                                                          Mobile No.:   +91 9932584135\n",
    "Degree/Certificate\n",
    "Dual Degree[B. Tech (H) + M. Tech]\n",
    "(Computer Science & Engineering)\n",
    "Class XII:  C.B.S.E.\n",
    "Class X:   C.B.S.E.\n",
    "ACADEMIC ACHIEVEMENTS\n",
    "Institute/ School, City\n",
    "Indian Institute of Technology, Kharagpur\n",
    "Central Hindu School, Varanasi\n",
    "St. Atulanand Convent School, Varanasi\n",
    "CGPA/ %  Completion\n",
    "8.26/10\n",
    "86.0%\n",
    "90.8%\n",
    "2011\n",
    "2005\n",
    "2003\n",
    "Competitive\n",
    "Examinations\n",
    "  All India Rank 116 in AIEEE, 2006 among 470,000 students, State Rank 8 in Uttar Pradesh.\n",
    "  All India Rank 119 in 7th National Science Olympiad, 2005.\n",
    "  All India Rank 22 in All India Level Mathematics & Science Test organized by Central Institute  for\n",
    "Proficiency in English Language (CIPEL).\n",
    "Scholastic\n",
    "Achievements\n",
    "  National top 1% out of 26968 candidates appeared in National Standard Examination in Physics’05\n",
    "  Receiving CBSE Merit Scholarship for the past 4 years.\n",
    "ACADEMIC PROJECTS\n",
    "M. Tech Project                                                                                      IIT Kharagpur                                           May’10-Nov’10\n",
    "•\n",
    "•\n",
    "Studied the performance of text indexing algorithms on Hadoop MapReduce architecture.\n",
    "Future work includes implementing more efficient indexing and retrieval techniques in MapReduce for distributed parallel\n",
    "computing.\n",
    "B. Tech Project                                                                                        IIT Kharagpur                                           Aug’09-May’10\n",
    "  Developed a software with can handle all sorts of query related to geographical information extracted from maps.\n",
    "  Developed a client interface which can fetch data from different incompatible geospatial web services and make that data\n",
    "compatible for resolving queries.\n",
    "Integrated my framework engine with different underlying heterogeneous spatial databases.\n",
    "\n",
    "Static Instrumentation Of Java Programs                                          IIT Kharagpur                                                   May’08\n",
    "  Developed a program using Byte Code Engineering Library to do automated testing of java program at byte code level.\n",
    "WORK EXPERIENCE / INTERNSHIP\n",
    "Extreme Blue Internship Program                                                                   ISL, IBM, Pune, India                                       May’09 – July’09\n",
    "Business\n",
    "Perspective\n",
    "Technical\n",
    "Perspective\n",
    " Achievements\n",
    "  Conducted survey in Pune region on the current home delivery status of organized retails\n",
    "\n",
    "Proposed and implemented a solution on how to increase home delivery sales in order to compete with the\n",
    "localized general (kirana) stores\n",
    "\n",
    "Built an independent Home Delivery module on Java EE platform using open standards such as XML and\n",
    "Web Services\n",
    "Integrated the Home Delivery module with IBM WebSphere Commerce.\n",
    "\n",
    "  Received highest grade 10/10 in summer internship evaluation at IIT Kharagpur, 2009.\n",
    "RELEVANT COURSES TAKEN\n",
    "  Machine learning\n",
    "  Algorithms-I\n",
    "  Algorithms-II\n",
    "Information Retrieval\n",
    "\n",
    "  Distributed Systems\n",
    "\n",
    "Probability and Statistics\n",
    "POSITION OF RESPONSIBILITY\n",
    "\n",
    "Student coordinator of IIT Kharagpur Student Counselling Service.\n",
    "  Student member of team that conceptualized and publicized Counselling Centre in IIT Kharagpur after 5 successive suicides\n",
    "in the campus within a span of 6 months in between Feb’09 and Jul’09.\n",
    "  More than 100 students are counselled every month.\n",
    "  No mishaps in the campus as of Sep’10 after the establishment of the centre.\n",
    "  Went through Gate Keepers Training to identify behavioral change in a person.\n",
    "  Managed  the  systems  team  of  Bitwise-2010,  an  international  algorithmic  intensive  programming  contest  leading  to  the\n",
    "participation of 3000 teams across 75 countries.\n",
    "\n",
    "Family Sub-head of accommodation team in Spring Fest, 2008.\n",
    "  Head boy of my Senior Secondary School (Central Hindu School).\n",
    "e\n",
    "EXTRA CURRICULAR ACHIEVEMENTS\n",
    "  Member of Silver winning team in inter hall OPENSOFT Competition in the session 2007-08.\n",
    "  National Sports Organization: Among Top 30 students in Lawn Tennis Team at IIT Kharagpur’06. ''']\n",
    "\n",
    "for doc in nlp.pipe(text, disable=[\"tagger\", \"parser\"]):\n",
    "    print([(ent.text, ent.label_) for ent in doc.ents])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ref: https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/\n",
    "\n",
    "# Import and load the spacy model\n",
    "import spacy\n",
    "import json\n",
    "from collections import Counter\n",
    "nlp_sm=spacy.load(\"en_core_web_sm\")\n",
    "# nlp_md=spacy.load(\"en_core_web_md\")\n",
    "# nlp_lg=spacy.load(\"en_core_web_lg\")\n",
    "# nlp_trf=spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# Getting the ner component\n",
    "if \"ner\" not in nlp_sm.pipe_names:\n",
    "    ner = nlp_sm.create_pipe(\"ner\")\n",
    "    nlp_sm.add_pipe(ner, last=True)\n",
    "else:\n",
    "    ner = nlp_sm.get_pipe(\"ner\")\n",
    "\n",
    "# Training examples in the required format\n",
    "with open('./train.spacy', \"r\", encoding=\"utf-8\") as train_data:\n",
    "\n",
    "    tab_ents =['CODE', 'DEM', 'MISC']\n",
    "    for ent in tab_ents:\n",
    "        ner.add_label(ent)\n",
    "\n",
    "    # Resume training\n",
    "    optimizer = nlp_sm.resume_training()\n",
    "    move_names = list(ner.move_names)\n",
    "\n",
    "    # List of pipes you want to train\n",
    "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "\n",
    "    # List of pipes which should remain unaffected in training\n",
    "    other_pipes = [pipe for pipe in nlp_sm.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "    # Importing requirements\n",
    "    from spacy.util import minibatch, compounding\n",
    "    import random\n",
    "\n",
    "    # Begin training by disabling other pipeline components\n",
    "    with nlp_sm.disable_pipes(*other_pipes) :\n",
    "\n",
    "      sizes = compounding(1.0, 4.0, 1.001)\n",
    "      # Training for 30 iterations\n",
    "      for itn in range(30):\n",
    "        # shuffle examples before training\n",
    "        random.shuffle(train_data)\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(train_data, size=sizes)\n",
    "        # dictionary to store losses\n",
    "        losses = {}\n",
    "        for batch in batches:\n",
    "          texts, annotations = zip(*batch)\n",
    "          # Calling update() over the iteration\n",
    "          nlp_sm.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "          print(\"Losses\", losses)\n",
    "\n",
    "    # Testing the NER\n",
    "\n",
    "    test_text = \"I ate Sushi yesterday. Maggi is a common fast food \"\n",
    "    doc = nlp_sm(test_text)\n",
    "    print(\"Entities in '%s'\" % test_text)\n",
    "    for ent in doc.ents:\n",
    "        print(ent)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Output directory\n",
    "from pathlib import Path\n",
    "output_dir=Path('../../data/models/spacy/')\n",
    "\n",
    "# Saving the model to the output directory\n",
    "if not output_dir.exists():\n",
    "  output_dir.mkdir()\n",
    "nlp_sm.meta['name'] = 'my_ner'  # rename model\n",
    "nlp_sm.to_disk(output_dir)\n",
    "print(\"Saved model to\", output_dir)\n",
    "\n",
    "# Loading the model from the directory\n",
    "print(\"Loading from\", output_dir)\n",
    "nlp2 = spacy.load(output_dir)\n",
    "assert nlp2.get_pipe(\"ner\").move_names == move_names\n",
    "doc2 = nlp2(' Dosa is an extremely famous south Indian dish')\n",
    "for ent in doc2.ents:\n",
    "  print(ent.label_, ent.text)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
